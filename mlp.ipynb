{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-30T13:16:50.515498Z",
     "start_time": "2025-12-30T13:16:46.882106Z"
    }
   },
   "source": [
    "from src.dataset import ATPMatchesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T13:16:50.559062Z",
     "start_time": "2025-12-30T13:16:50.550131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "\n",
    "class StandardizeTransform:\n",
    "    def __init__(self, numerical_indices, fit_data=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            numerical_indices: List of indices for numerical features to standardize\n",
    "            fit_data: Data to fit the scaler on (typically training data features)\n",
    "        \"\"\"\n",
    "        self.numerical_indices = numerical_indices\n",
    "        self.scaler = MinMaxScaler()\n",
    "        if fit_data is not None:\n",
    "            # Extract only numerical features for fitting\n",
    "            numerical_data = fit_data[:, numerical_indices]\n",
    "            self.scaler.fit(numerical_data)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        features = sample['features'].clone()\n",
    "\n",
    "        # Extract numerical features, transform, and put back\n",
    "        numerical_features = features[self.numerical_indices]\n",
    "        standardized = torch.tensor(\n",
    "            self.scaler.transform(numerical_features.unsqueeze(0).numpy())[0],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        features[self.numerical_indices] = standardized\n",
    "\n",
    "        return {'features': features, 'target': sample['target']}"
   ],
   "id": "9830adcb8049639f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T13:16:52.345359Z",
     "start_time": "2025-12-30T13:16:50.872063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = ATPMatchesDataset('data/processed/atp_matches_2000_2024_final.csv')\n",
    "\n",
    "train_loader = DataLoader(dataset.TRAIN, batch_size=32, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dataset.DEV, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(dataset.TEST, batch_size=32, shuffle=False, num_workers=4)"
   ],
   "id": "12c3cea20cd5bdc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T13:16:52.359649Z",
     "start_time": "2025-12-30T13:16:52.352290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ATPMatchPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[128, 64, 32]):\n",
    "        super(ATPMatchPredictor, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Hidden layers\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.3))\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Output layer (binary classification)\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "id": "5ccfb2cae72aa9d8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T13:16:52.417657Z",
     "start_time": "2025-12-30T13:16:52.378824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "e7d5ca88c2e8c24b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-30T13:16:52.480717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get input size from first batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "features = sample_batch['features']\n",
    "labels = sample_batch['target']\n",
    "input_size = features.shape[1]\n",
    "\n",
    "print(f\"Input size: {input_size}\")\n",
    "\n",
    "# Initialize model and move to device\n",
    "model = ATPMatchPredictor(input_size=input_size, hidden_sizes=[128, 64, 32])\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        features = batch['features'].to(device)  # Move to device\n",
    "        labels = batch['target'].float().to(device)  # Move to device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    dev_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            features = batch['features'].to(device)  # Move to device\n",
    "            labels = batch['target'].float().to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            dev_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs.squeeze() > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "          f'Dev Loss: {dev_loss/len(dev_loader):.4f}, '\n",
    "          f'Dev Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "377d0536922f1fcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 216\n",
      "ATPMatchPredictor(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=216, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Epoch [1/50], Train Loss: 0.5824, Dev Loss: 0.5462, Dev Accuracy: 70.91%\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "64f8cc2eb08e72cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
